{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f99cf61",
   "metadata": {},
   "source": [
    "# Working with JSON data in PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54456b0a",
   "metadata": {},
   "source": [
    "- JSON stands for JavaScript Object Notation. JSON data is a long-standing data interchange format that became massively popular for its readability and its relatively small size. \n",
    "\n",
    "- JSON consists of key and value pair. Keys are always strings, and values can take numerical, Boolean, string, or null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff0e8a",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb80406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d69123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a file\n",
    "shows = spark.read.json(\"./data/shows/shows-silicon-valley.json\") \n",
    "shows.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12d9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading many files \n",
    "three_shows = spark.read.json(\"./data/shows/shows-*.json\", multiLine=True)\n",
    "three_shows.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebc5eb",
   "metadata": {},
   "source": [
    "## 2. Breaking the second dimension with complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00da79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: string (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c51ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_embedded', '_links', 'externals', 'genres', 'id', 'image', 'language', 'name', 'network', 'officialSite', 'premiered', 'rating', 'runtime', 'schedule', 'status', 'summary', 'type', 'updated', 'url', 'webChannel', 'weight']\n"
     ]
    }
   ],
   "source": [
    "print(shows.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3981659",
   "metadata": {},
   "source": [
    "### 2.1 When you have more than one value: The array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130ebbc",
   "metadata": {},
   "source": [
    "PySpark arrays are containers for values of the same type. To work a little with the array, let's get a subset from the show dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bf813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|          name|  genres|\n",
      "+--------------+--------+\n",
      "|Silicon Valley|[Comedy]|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting two columns\n",
    "array_subset = shows.select(\"name\", \"genres\")\n",
    "array_subset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a6f27",
   "metadata": {},
   "source": [
    "To take to the value inside the array, you need to extract them. There are many ways to exract elements from an array. Let me show that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c349a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "|          name|dot_and_index|col_and_index|dot_and_method|col_and_method|\n",
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "|Silicon Valley|       Comedy|       Comedy|        Comedy|        Comedy|\n",
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "array_subset = array_subset.select(\n",
    "    \"name\",\n",
    "    array_subset.genres[0].alias(\"dot_and_index\"), \n",
    "    F.col(\"genres\")[0].alias(\"col_and_index\"),\n",
    "    array_subset.genres.getItem(0).alias(\"dot_and_method\"), \n",
    "    F.col(\"genres\").getItem(0).alias(\"col_and_method\"),\n",
    ")\n",
    "array_subset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed31fdf",
   "metadata": {},
   "source": [
    "Let's take a look at how to perform multiple operations on an array column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64dd9252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+----------------------------------------+\n",
      "|name          |Some_Genres            |Repeated_Genres                         |\n",
      "+--------------+-----------------------+----------------------------------------+\n",
      "|Silicon Valley|[Comedy, Horror, Drama]|[Comedy, Comedy, Comedy, Comedy, Comedy]|\n",
      "+--------------+-----------------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array_subset_repeated = array_subset.select(\n",
    "    \"name\",\n",
    "    # lit() is used to create scalar columns.\n",
    "    F.lit(\"Comedy\").alias(\"one\"),\n",
    "    F.lit(\"Horror\").alias(\"two\"),\n",
    "    F.lit(\"Drama\").alias(\"three\"),\n",
    "    F.col(\"dot_and_index\"),\n",
    ").select(\n",
    "    \"name\",\n",
    "    # The array method is used to create an array.\n",
    "    F.array(\"one\", \"two\", \"three\").alias(\"Some_Genres\"), \n",
    "    # The array_repeat is used to repeat the values five times within an array.\n",
    "    F.array_repeat(\"dot_and_index\", 5).alias(\"Repeated_Genres\"), \n",
    ")\n",
    "array_subset_repeated.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef42887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+---------------------+\n",
      "|          name|size(Some_Genres)|size(Repeated_Genres)|\n",
      "+--------------+-----------------+---------------------+\n",
      "|Silicon Valley|                3|                    5|\n",
      "+--------------+-----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the size method\n",
    "array_subset_repeated.select(\n",
    "    \"name\", \n",
    "    # The size method is used to compute a number of elements.\n",
    "    F.size(\"Some_Genres\"), F.size(\"Repeated_Genres\") \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04e89ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------+-------------------------------+\n",
      "|name          |array_distinct(Some_Genres)|array_distinct(Repeated_Genres)|\n",
      "+--------------+---------------------------+-------------------------------+\n",
      "|Silicon Valley|[Comedy, Horror, Drama]    |[Comedy]                       |\n",
      "+--------------+---------------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the array_distrinct method\n",
    "array_subset_repeated.select(\n",
    "    \"name\",\n",
    "    # The array_distrinct method is used to remove duplicate values.\n",
    "    F.array_distinct(\"Some_Genres\"),\n",
    "    F.array_distinct(\"Repeated_Genres\"), \n",
    ").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a809625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|          name|  Genres|\n",
      "+--------------+--------+\n",
      "|Silicon Valley|[Comedy]|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the array_intersect method.\n",
    "array_subset_repeated = array_subset_repeated.select(\n",
    "    \"name\",\n",
    "    # The array_intersect method is used to look at intersect values.\n",
    "    F.array_intersect(\"Some_Genres\", \"Repeated_Genres\").alias(\"Genres\"),\n",
    ")\n",
    "array_subset_repeated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca86e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+\n",
      "|  Genres|array_position(Genres, Comedy)|\n",
      "+--------+------------------------------+\n",
      "|[Comedy]|                             1|\n",
      "+--------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the array_position method\n",
    "array_subset_repeated.select(\n",
    "    \"Genres\", \n",
    "    # The array_position method is used to look at the position of a value in array.\n",
    "    F.array_position(\"Genres\", \"Comedy\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78e1a7",
   "metadata": {},
   "source": [
    "### 2.2 The map type: Keys and values within a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ba936",
   "metadata": {},
   "source": [
    "A map has keys and values just like in a dictionary. One of the easiest ways to create a map is from two columns of type array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ec9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                keys|              values|\n",
      "+--------------------+--------------------+\n",
      "|[name, language, ...|[Silicon Valley, ...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a map\n",
    "columns = [\"name\", \"language\", \"type\"]\n",
    "shows_map = shows.select(\n",
    "    *[F.lit(column) for column in columns],\n",
    "    F.array(*columns).alias(\"values\"),\n",
    ")\n",
    "shows_map = shows_map.select(F.array(*columns).alias(\"keys\"), \"values\")\n",
    "shows_map.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b19993c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_map = shows_map.select(\n",
    "    F.map_from_arrays(\"keys\", \"values\").alias(\"mapped\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e330af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mapped: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_map.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e8fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------+\n",
      "|mapped                                                         |\n",
      "+---------------------------------------------------------------+\n",
      "|[name -> Silicon Valley, language -> English, type -> Scripted]|\n",
      "+---------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_map.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca75455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+\n",
      "|          name|  mapped[name]|  mapped[name]|\n",
      "+--------------+--------------+--------------+\n",
      "|Silicon Valley|Silicon Valley|Silicon Valley|\n",
      "+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_map.select(\n",
    "    F.col(\"mapped.name\"), \n",
    "    F.col(\"mapped\")[\"name\"], \n",
    "    shows_map.mapped[\"name\"], \n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca99bf",
   "metadata": {},
   "source": [
    "You can get the value corresponding to a key using the dot notation within the col function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd7832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+\n",
      "|          name|  mapped[name]|  mapped[name]|\n",
      "+--------------+--------------+--------------+\n",
      "|Silicon Valley|Silicon Valley|Silicon Valley|\n",
      "+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_map.select(\n",
    "    F.col(\"mapped.name\"), \n",
    "    F.col(\"mapped\")[\"name\"], \n",
    "    shows_map.mapped[\"name\"], \n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c914f",
   "metadata": {},
   "source": [
    " ## 3. The struct: Nesting columns within columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4db22",
   "metadata": {},
   "source": [
    "The struct is similar to a JSON object. So the key or name of each pair is a string and that each record can be of a different type. Let's select a subset from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96bf6b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows.select(\"schedule\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4700d5",
   "metadata": {},
   "source": [
    "Here, the schedule column is a struct. The struct contains two named fields: days (an Array) and time, a string. As a result, you can think of the struct as **a small data frame** within your column records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d2be0",
   "metadata": {},
   "source": [
    "### 3.1 Navigating structs as if they were nested columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6361544",
   "metadata": {},
   "source": [
    "Let's look at how to extract values from nested structs inside a data frame using the embedded column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de53f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: string (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows.select(F.col(\"_embedded\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4e8c3",
   "metadata": {},
   "source": [
    "The embedded column only contain a field, episodes. Let's access this field using the dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c7f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      " |-- episodes: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |-- airstamp: string (nullable = true)\n",
      " |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- number: long (nullable = true)\n",
      " |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |-- season: long (nullable = true)\n",
      " |    |    |-- summary: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_clean = shows.withColumn(\"episodes\", F.col(\"_embedded.episodes\")).drop(\"_embedded\")\n",
    "shows_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8867e72",
   "metadata": {},
   "source": [
    "Here, we drop the embedded column  and promoted the field of the struct (episodes) as a top level column.  Now, let's select a field in an Array to create a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81adbdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episodes_name = shows_clean.select(F.col(\"episodes.name\"))\n",
    "episodes_name.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b4c7f",
   "metadata": {},
   "source": [
    "## 4. Building and using the data frame schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea23bc",
   "metadata": {},
   "source": [
    "This section cover how to define and use a schema with a PySpark data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed24842",
   "metadata": {},
   "source": [
    "### 4.1 Using Spark types as the base blocks of a schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ad025",
   "metadata": {},
   "source": [
    "In this subsection, I explain the column types in the context of a schema definition. The data types we use to build a schema are located in the pyspark.sql.types module. Let's import this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d25501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cb282",
   "metadata": {},
   "source": [
    "Within the pyspark.sql.types, there are two main kinds of objects: First, you have the types object such as  the ValueType(), LongType() that represents a column of a certain type. Second, you have the field object: the StructField()\n",
    "\n",
    "A StructField() contains two mandatory as well as two optional parameters:\n",
    "- The name of the field, passed as a string\n",
    "- The dataType of the field, passed as a type object\n",
    "- (Optional) A nullable flag, which determines if the field can be null or not\n",
    "(by default True)\n",
    "- (Optional) A metadata dictionary that contains arbitrary information, which we\n",
    "will use for column metadata when working with ML pipelines.\n",
    "\n",
    "Let' take a look at the schema for the embedded field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9bd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The _links field contains a self struct that itself contains a single-string field: href.\n",
    "episode_links_schema = T.StructType(\n",
    "    [T.StructField(\"self\", T.StructType([T.StructField(\"href\", T.StringType())]))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8401462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image field is a struct of two string fields: medium and original.\n",
    "episode_image_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"medium\", T.StringType()), \n",
    "        T.StructField(\"original\", T.StringType()),\n",
    "    ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75d142c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"_links\", episode_links_schema), \n",
    "        T.StructField(\"airdate\", T.DateType()),\n",
    "        T.StructField(\"airstamp\", T.TimestampType()),\n",
    "        T.StructField(\"airtime\", T.StringType()),\n",
    "        T.StructField(\"id\", T.StringType()),\n",
    "        T.StructField(\"image\", episode_image_schema), \n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "        T.StructField(\"number\", T.LongType()),\n",
    "        T.StructField(\"runtime\", T.LongType()),\n",
    "        T.StructField(\"season\", T.LongType()),\n",
    "        T.StructField(\"summary\", T.StringType()),\n",
    "        T.StructField(\"url\", T.StringType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3978062",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\n",
    "            \"_embedded\",\n",
    "            T.StructType(\n",
    "                [\n",
    "                    T.StructField(\n",
    "                    \"episodes\", T.ArrayType(episode_schema))\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1b7cb",
   "metadata": {},
   "source": [
    "### 4.2 Reading a JSON document with a strict schema in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931f105",
   "metadata": {},
   "source": [
    "In this section I'm going to talk about how to read a JSON document while enforcing a precise schema. Let's read a JSON document with an explicit partial schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc3ddf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_with_schema = spark.read.json(\n",
    "    \"./data/shows/shows-silicon-valley.json\",\n",
    "    #  we only read the defined fields.\n",
    "    schema=embedded_schema, \n",
    "    # To crash DataFrameReader if our schema is incompatible\n",
    "    mode=\"FAILFAST\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1246e",
   "metadata": {},
   "source": [
    "Let's verify the new date and timestamp field with the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9e8294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|       col|\n",
      "+----------+\n",
      "|2014-04-06|\n",
      "|2014-04-13|\n",
      "|2014-04-20|\n",
      "|2014-04-27|\n",
      "|2014-05-04|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|2014-04-07T02:00:...|\n",
      "|2014-04-14T02:00:...|\n",
      "|2014-04-21T02:00:...|\n",
      "|2014-04-28T02:00:...|\n",
      "|2014-05-05T02:00:...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in [\"airdate\", \"airstamp\"]:\n",
    "    shows.select(f\"_embedded.episodes.{column}\").select(\n",
    "    F.explode(column)\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e4865",
   "metadata": {},
   "source": [
    "Here you go. Everything looks fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59412486",
   "metadata": {},
   "source": [
    "### 4.3 Going full circle: Specifying your schemas in JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fbd56",
   "metadata": {},
   "source": [
    "In this section, I'll cover a different approach to the schema definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ad9ca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': [{'metadata': {},\n",
      "             'name': 'airtime',\n",
      "             'nullable': True,\n",
      "             'type': 'string'}],\n",
      " 'type': 'struct'}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-printing the schema\n",
    "import pprint\n",
    "pprint.pprint(\n",
    "    shows_with_schema.select(\n",
    "        F.explode(\"_embedded.episodes\").alias(\"episode\")\n",
    "    )\n",
    "    .select(\"episode.airtime\")\n",
    "    .schema.jsonValue()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83a7ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {},\n",
      " 'name': 'array_example',\n",
      " 'nullable': True,\n",
      " 'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-printing dummy complex types\n",
    "pprint.pprint(\n",
    "    T.StructField(\"array_example\", T.ArrayType(T.StringType())).jsonValue()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42d3dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {},\n",
      " 'name': 'map_example',\n",
      " 'nullable': True,\n",
      " 'type': {'keyType': 'string',\n",
      "          'type': 'map',\n",
      "          'valueContainsNull': True,\n",
      "          'valueType': 'long'}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\n",
    "    T.StructField(\n",
    "    \"map_example\", T.MapType(T.StringType(), T.LongType())\n",
    "    ).jsonValue()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace3440",
   "metadata": {},
   "source": [
    "## 5 Reducing duplicate data with complex data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0004dd",
   "metadata": {},
   "source": [
    "This section takes the hierarchical data model and presents the advantages in a big\n",
    "data setting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299eba31",
   "metadata": {},
   "source": [
    "### 5.1 Getting to the “just right” data frame: Explode and collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c6469",
   "metadata": {},
   "source": [
    "This section covers how to use explode and collect operations to go from hierarchi\u0002cal to tabular and back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44351d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------+\n",
      "| id|                                                              episodes|\n",
      "+---+----------------------------------------------------------------------+\n",
      "|143|[[[http://api.tvmaze.com/episodes/10897]], 2014-04-06, 2014-04-07T0...|\n",
      "|143|[[[http://api.tvmaze.com/episodes/10898]], 2014-04-13, 2014-04-14T0...|\n",
      "|143|[[[http://api.tvmaze.com/episodes/10899]], 2014-04-20, 2014-04-21T0...|\n",
      "|143|[[[http://api.tvmaze.com/episodes/10900]], 2014-04-27, 2014-04-28T0...|\n",
      "|143|[[[http://api.tvmaze.com/episodes/10901]], 2014-05-04, 2014-05-05T0...|\n",
      "+---+----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploding the _embedded.episodes into 53 distinct records\n",
    "episodes = shows.select(\n",
    "    \"id\", F.explode(\"_embedded.episodes\").alias(\"episodes\")\n",
    ") \n",
    "episodes.show(5, truncate=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8a51105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------------------+\n",
      "|position|   id|                name|\n",
      "+--------+-----+--------------------+\n",
      "|       0|10897|Minimum Viable Pr...|\n",
      "|       1|10898|       The Cap Table|\n",
      "|       2|10899|Articles of Incor...|\n",
      "|       3|10900|    Fiduciary Duties|\n",
      "|       4|10901|      Signaling Risk|\n",
      "+--------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploding a map using posexplode()\n",
    "episode_name_id = shows.select(\n",
    "    F.map_from_arrays( \n",
    "    F.col(\"_embedded.episodes.id\"), F.col(\"_embedded.episodes.name\")\n",
    "    ).alias(\"name_id\")\n",
    ")\n",
    "episode_name_id = episode_name_id.select(\n",
    "    F.posexplode(\"name_id\").alias(\"position\", \"id\", \"name\") \n",
    ")\n",
    "episode_name_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42dd5bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting our results back into an array\n",
    "collected = episodes.groupby(\"id\").agg(\n",
    "    F.collect_list(\"episodes\").alias(\"episodes\")\n",
    ")\n",
    "collected.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bf9c6",
   "metadata": {},
   "source": [
    "### 5.2 Building your own hierarchies: Struct as a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b96c5b",
   "metadata": {},
   "source": [
    "This section concludes the chapter by showing how you can create structs within a data frame. The struct function can take one or more column objects (or column names). I passed a literal column to indicate that I’ve watched the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8018e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a struct column using the struct function\n",
    "struct_ex = shows.select(\n",
    "    F.struct( \n",
    "        F.col(\"status\"), F.col(\"weight\"), F.lit(True).alias(\"has_watched\")\n",
    "    ).alias(\"info\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d26978a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|info             |\n",
      "+-----------------+\n",
      "|[Ended, 96, true]|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "struct_ex.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30c9186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- info: struct (nullable = false)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- weight: long (nullable = true)\n",
      " |    |-- has_watched: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "struct_ex.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb2b26",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d213e",
   "metadata": {},
   "source": [
    "In this notebook, We ingested, processed, navigated, and molded a JSON document with the same data frame and set of functions that we used for textual and tabular data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed6759",
   "metadata": {},
   "source": [
    "### Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a2a37",
   "metadata": {},
   "source": [
    "- You can use JSON DataFrameReader for ingesting JSON documents within a data frame.\n",
    "\n",
    "- You can think of JSON data as a Python dictionary.\n",
    "\n",
    "- In PySpark, hierarchical data models are represented through complex column types. For example, the array represents lists of elements of the same type, the map represents multiple keys and values and the struct represents an object in the JSON sense.\n",
    "\n",
    "- PySpark offers a programatic API to build data frame schemas on top of a JSON representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b14fde",
   "metadata": {},
   "source": [
    "Thanks for reading. I hope you enjoy it 😀\n",
    "\n",
    "Don't forget to follow us on [YouTube](http://youtube.com/tirendazacademy) | [Medium](http://tirendazacademy.medium.com) | [Twitter](http://twitter.com/tirendazacademy) | [GitHub](http://github.com/tirendazacademy) | [Linkedin](https://www.linkedin.com/in/tirendaz-academy) | [Kaggle](https://www.kaggle.com/tirendazacademy) 😎"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c934845",
   "metadata": {},
   "source": [
    "## Resource\n",
    "- Data Analysis with Python and PySpark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
